{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 3: Support Vector Machines (SVM) & kernel methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will try to predict the species of a penguin from its physical characteristics using support vector machines (SVM).\n",
    "\n",
    "For this we will use the *palmerpenguins* dataset, an alternative to the now classic *iris* of scikit-learn. It contains the characteristics of three species of penguins found on the Palmer Archipelago, off the northwest coast of the Antarctic Peninsula.\n",
    "\n",
    "For more information, you can visit the website: https://allisonhorst.github.io/palmerpenguins/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T14:45:37.554027Z",
     "start_time": "2019-11-05T14:45:37.096188Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I- Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) with pip\n",
    "To install the package to access the data: **pip install palmerpenguins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from palmerpenguins import load_penguins\n",
    "palmerpenguins = load_penguins()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) in csv format\n",
    "If you do not have *pip* and cannot download the package in any other way, you have the data in .csv format in moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "palmerpenguins = pd.read_csv(\"palmerpenguins_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II- Dataset description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  year  \n",
       "0       3750.0    male  2007  \n",
       "1       3800.0  female  2007  \n",
       "2       3250.0  female  2007  \n",
       "3          NaN     NaN  2007  \n",
       "4       3450.0  female  2007  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palmerpenguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(344, 8)\n",
      "Counter({'Adelie': 152, 'Gentoo': 124, 'Chinstrap': 68})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "print(palmerpenguins.shape)\n",
    "print(collections.Counter(palmerpenguins.species))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**344** penguins with **8** attributes:\n",
    "- *species*: Adelie (152 penguins), Gentoo (124 penguins) and Ginstrap (68 penguins)\n",
    "- *island* (the census island): Biscoe, Dream and Torgersen\n",
    "- *bill_length_mm*: length of the bill in mm\n",
    "- *bil_depth_mm*: width of the bill in mm\n",
    "- *flipper_length_mm*: width of flippers in mm\n",
    "- *body_mass_g*: weight in g\n",
    "- *sex*: male and female\n",
    "- *year*: year of census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palmerpenguins.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You notice that there are some observations for which information is missing. This is known as **missing values**. \n",
    "Here we decide to ignore these observations. This leaves us with 342 labels to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palmerpenguins = palmerpenguins[palmerpenguins['bill_depth_mm'].notna()]\n",
    "palmerpenguins = palmerpenguins.reset_index()\n",
    "palmerpenguins.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of ignoring incomplete observations, a solution which is often better (from the point of view of the performance of data-driven decision models) is to **estimate** (or **impute**) the missing data and treat the estimated values as measured values.  \n",
    "\n",
    "For this we could have used the *SimpleImputer* function of *sklearn.impute*. For more information, you can go to the site: https://scikit-learn.org/stable/modules/impute.html#impute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of the tutorial, we will only be interested in the numerical features *bill_depth_mm*, *bill_length_mm*, *flipper_length_mm* and *body_mass_g*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_features = palmerpenguins[[\"bill_length_mm\", \"bill_depth_mm\",\"body_mass_g\", \"flipper_length_mm\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to predict the species, which correspond to the attribute **species** but encoded as integer. It will then be easier to handle the species as integers than as characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_names, species_int = np.unique(palmerpenguins.species, return_inverse=True)\n",
    "print(species_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_labels = pd.DataFrame(palmerpenguins[\"species\"])\n",
    "penguins_labels[\"species_int\"] = species_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III- SVM with a linear kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Standard case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the time being, we will limit ourselves to **two species (labels)**. : **Adelie (0)** and **Gentoo (2)**; and **two features** : *body_mass_g* et *bill_length_mm*.\n",
    " \n",
    "We will train a **linear SVM**.\n",
    "we will use the [SVC] class (http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) from the *svm* module of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T14:45:38.159339Z",
     "start_time": "2019-11-05T14:45:38.093422Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T14:45:38.169688Z",
     "start_time": "2019-11-05T14:45:38.160986Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select the 2 features\n",
    "data = penguins_features[penguins_labels[\"species_int\"].isin([0,2])] \n",
    "data = np.array(data[[\"body_mass_g\", \"bill_length_mm\"]])\n",
    "# data = np.array(data[[\"body_mass_g\", \"flipper_length_mm\"]])\n",
    "print(\"X shape:\", data.shape)\n",
    "\n",
    "# select the corresponding labels\n",
    "labels = penguins_labels[penguins_labels[\"species_int\"].isin([0,2])]\n",
    "labels = np.array(labels[\"species_int\"])\n",
    "print(\"y shape:\", labels.shape)\n",
    "\n",
    "# initialize a model\n",
    "clf = svm.SVC(kernel='linear', C=10)\n",
    "\n",
    "# fit the model\n",
    "clf.fit(X= data, y = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the performance of the predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T14:45:38.926632Z",
     "start_time": "2019-11-05T14:45:38.922976Z"
    }
   },
   "outputs": [],
   "source": [
    "print(clf.score(data, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Which performance measure is calculated by [`clf.score`](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.score) ?\n",
    "\n",
    "__Answer :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature standardisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardise the features (by removing their mean and dividing by their standard deviation) and see if this has an influence on the performance of the SVM. This task is fully automated by `scikit-learn` :\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Select the 2 features\n",
    "data = penguins_features[penguins_labels[\"species_int\"].isin([0,2])] \n",
    "#data = np.array(data[[\"body_mass_g\", \"bill_length_mm\"]])\n",
    "data = np.array(data[[\"body_mass_g\", \"flipper_length_mm\"]])\n",
    "\n",
    "# Scale them\n",
    "std_scale = preprocessing.StandardScaler().fit(data)\n",
    "data_scaled = std_scale.transform(data)\n",
    "\n",
    "# select the corresponding labels\n",
    "labels = penguins_labels[penguins_labels[\"species_int\"].isin([0,2])]\n",
    "labels = np.array(labels[\"species_int\"])\n",
    "\n",
    "# initialize a model\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "\n",
    "# fit the model\n",
    "clf.fit(X= data_scaled, y = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent the separating hyperplane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# plot the point cloud\n",
    "adelie = plt.scatter(data_scaled[np.where(penguins_labels[\"species_int\"]==0),0], \n",
    "                    data_scaled[np.where(penguins_labels[\"species_int\"]==0),1], \n",
    "                    color=\"royalblue\", \n",
    "                    s=50, \n",
    "                    label = 'Adelie',\n",
    "                    cmap=plt.cm.Paired)\n",
    "\n",
    "gentoo = plt.scatter(data_scaled[np.where(penguins_labels[\"species_int\"]==2),0], \n",
    "                    data_scaled[np.where(penguins_labels[\"species_int\"]==2),1], \n",
    "                    color=\"gold\", \n",
    "                    s=50, \n",
    "                    label = 'Gentoo',\n",
    "                    cmap=plt.cm.Paired)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# get frame limits\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# visualize support vectors with a cross\n",
    "ax.scatter(clf.support_vectors_[:, 0], \n",
    "           clf.support_vectors_[:, 1], \n",
    "           s=50, \n",
    "           linewidth=1, \n",
    "           marker='x', \n",
    "           color='k')\n",
    "\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], \n",
    "           alpha=0.5, linestyles=['--', '-', '--'])\n",
    "\n",
    "# format the plot\n",
    "plt.xticks(fontweight=\"bold\", fontsize=15)\n",
    "plt.yticks(fontweight=\"bold\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.score(data_scaled, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ What is the effect of feature standardisation on the performance of the classifier? How can you interpret it?\n",
    "\n",
    "__Answer :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of the tutorial, we will therefore standardise all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(penguins_features)\n",
    "penguins_features_scaled = pd.DataFrame(std_scale.transform(penguins_features), columns=penguins_features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perfect case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we will look at the features **bill_length_mm** and **bill_depth_mm**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the 2 features\n",
    "data = penguins_features_scaled[penguins_labels[\"species_int\"].isin([0,2])] \n",
    "data = np.array(data[[\"bill_length_mm\",\"bill_depth_mm\"]])\n",
    "print(\"X shape:\", data.shape)\n",
    "\n",
    "# select the corresponding labels\n",
    "labels = penguins_labels[penguins_labels[\"species_int\"].isin([0,2])]\n",
    "labels = np.array(labels[\"species_int\"])\n",
    "print(\"y shape:\", labels.shape)\n",
    "\n",
    "# initialize a model\n",
    "clf = svm.SVC(kernel='linear', C=10000)\n",
    "\n",
    "# fit the model\n",
    "clf.fit(X= data, y = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# plot the point cloud\n",
    "adelie = plt.scatter(penguins_features_scaled[penguins_labels[\"species_int\"]==0]['bill_length_mm'], \n",
    "                     penguins_features_scaled[penguins_labels[\"species_int\"]==0]['bill_depth_mm'], \n",
    "                    color=\"royalblue\", \n",
    "                    s=50, \n",
    "                    label = 'Adelie',\n",
    "                    cmap=plt.cm.Paired)\n",
    "\n",
    "gentoo = plt.scatter(penguins_features_scaled[penguins_labels[\"species_int\"]==2]['bill_length_mm'], \n",
    "                    penguins_features_scaled[penguins_labels[\"species_int\"]==2]['bill_depth_mm'], \n",
    "                    color=\"gold\", \n",
    "                    s=50, \n",
    "                    label = 'Gentoo',\n",
    "                    cmap=plt.cm.Paired)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# get frame limits\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# visualize support vectors with a cross\n",
    "ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], \n",
    "           s=50, linewidth=1, marker='x', color='k')\n",
    "\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0], \n",
    "           alpha=0.5, linestyles=['--', '-'])\n",
    "\n",
    "# format the plot\n",
    "plt.xticks(fontweight=\"bold\", fontsize=15)\n",
    "plt.yticks(fontweight=\"bold\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ What does a performance of 1.0 mean? Which points are the support vectors? \n",
    "\n",
    "__Answer :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Gram matrix representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **kernel** can be interpreted as a similarity matrix between different observations. We then rely on the similarity of some observations to be able to classify them. \n",
    "\n",
    "We will represent the Gram matrix from the previous classifier. In the case of a linear kernel SVM, it is to the scalar product of the features. In order to give you a good feeling of the **similarity** between the observations, ther Gram matrix will be reduced to a matrix with 1s on the diagonal using the *center_an_normalise_kernel()* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def center_and_normalise_kernel(K_temp):\n",
    "\n",
    "    K_temp = preprocessing.KernelCenterer().fit_transform(K_temp)\n",
    "    nb_item = K_temp.shape[0]\n",
    "    K_norm = np.zeros((nb_item, nb_item))\n",
    "    for i in range(nb_item):\n",
    "        for j in range(i, nb_item):\n",
    "            K_norm[i, j] = K_temp[i, j] / math.sqrt(K_temp[i, i] * K_temp[j, j])\n",
    "            K_norm[j, i] = K_norm[i, j]\n",
    "\n",
    "    return K_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GramMatrix = np.inner(data, data)\n",
    "GramMatrix_scaled = center_and_normalise_kernel(GramMatrix)\n",
    "\n",
    "# heatmap + color map\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "plot = ax.imshow(GramMatrix_scaled) \n",
    "\n",
    "# set axes boundaries\n",
    "ax.set_xlim([0, data.shape[0]]) ; ax.set_ylim([0, data.shape[0]])\n",
    "\n",
    "# flip the y-axis\n",
    "ax.invert_yaxis() ; ax.xaxis.tick_top()\n",
    "\n",
    "# plot colorbar to the right\n",
    "plt.colorbar(plot, pad=0.1, fraction=0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question:__ What do you notice? Could you have anticipated that the classifier \"separates\" well by looking at the Gram matrix?\n",
    "\n",
    "__Answer:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jj/v4bcmf8n3_q3_rl3s3q7pwt40000gn/T/ipykernel_17108/1995620650.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGramMatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mGramMatrix_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcenter_and_normalise_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGramMatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGramMatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "GramMatrix = np.inner(data, data)\n",
    "GramMatrix_scaled = center_and_normalise_kernel(GramMatrix)\n",
    "\n",
    "r = GramMatrix.shape[0]\n",
    "pr = np.random.permutation(np.arange(r))\n",
    "\n",
    "\n",
    "# heatmap + color map\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "plot = ax.imshow(GramMatrix_scaled[pr,:]) \n",
    "\n",
    "# set axes boundaries\n",
    "ax.set_xlim([0, data.shape[0]]) ; ax.set_ylim([0, data.shape[0]])\n",
    "\n",
    "# flip the y-axis\n",
    "ax.invert_yaxis() ; ax.xaxis.tick_top()\n",
    "\n",
    "# plot colorbar to the right\n",
    "plt.colorbar(plot, pad=0.1, fraction=0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.b\n",
    "\n",
    "__Question:__ What do you observe? What should we look out for when we observe a Gram matrix?\n",
    "\n",
    "__Answer:__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. A slightly more complicated case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider the two species: **Adelie (0)** and **Chinstrap (1)** and the features *body_mass_g* and *bill_depth_mm*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'penguins_features_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jj/v4bcmf8n3_q3_rl3s3q7pwt40000gn/T/ipykernel_17108/2375914705.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Select the 2 features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpenguins_features_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpenguins_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"species_int\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bill_depth_mm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"body_mass_g\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'penguins_features_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# Select the 2 features\n",
    "data = penguins_features_scaled[penguins_labels[\"species_int\"].isin([0,1])] \n",
    "data = np.array(data[[\"bill_depth_mm\", \"body_mass_g\"]])\n",
    "print(\"X shape:\", data.shape)\n",
    "\n",
    "# select the corresponding labels\n",
    "labels = penguins_labels[penguins_labels[\"species_int\"].isin([0,1])]\n",
    "labels = np.array(labels[\"species_int\"])\n",
    "print(\"y shape:\", labels.shape)\n",
    "\n",
    "# initialize a model\n",
    "clf = svm.SVC(kernel='linear', C=10)\n",
    "\n",
    "# fit the model\n",
    "clf.fit(X= data, y = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T14:45:39.675432Z",
     "start_time": "2019-11-05T14:45:38.951291Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# plot the point cloud\n",
    "adelie = plt.scatter(penguins_features_scaled[penguins_labels[\"species_int\"]==0]['bill_depth_mm'], \n",
    "                     penguins_features_scaled[penguins_labels[\"species_int\"]==0]['body_mass_g'], \n",
    "                    color=\"royalblue\", \n",
    "                    s=50, \n",
    "                    label = 'Adelie',\n",
    "                    cmap=plt.cm.Paired)\n",
    "\n",
    "gentoo = plt.scatter(penguins_features_scaled[penguins_labels[\"species_int\"]==1]['bill_depth_mm'], \n",
    "                    penguins_features_scaled[penguins_labels[\"species_int\"]==1]['body_mass_g'], \n",
    "                    color=\"lightgreen\", \n",
    "                    s=50, \n",
    "                    label = 'Chinstrap',\n",
    "                    cmap=plt.cm.Paired)\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# get frame limits\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.set_xlim(-2,2)\n",
    "ax.set_ylim(-2,2)\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# visualize support vectors with a cross\n",
    "ax.scatter(clf.support_vectors_[:, 0], \n",
    "           clf.support_vectors_[:, 1], \n",
    "           s=50, \n",
    "           linewidth=1, \n",
    "           marker='x', \n",
    "           color='k')\n",
    "\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=0, \n",
    "           alpha=0.5, linestyles=[ '-',])\n",
    "\n",
    "\n",
    "# format the plot\n",
    "plt.xticks(fontweight=\"bold\", fontsize=15)\n",
    "plt.yticks(fontweight=\"bold\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With graphics, it is really not easy to separate the two species with a line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.a\n",
    "\n",
    "__Question:__ How well does this model perform? What does the algorithm predict?\n",
    "\n",
    "__Answer:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent the Gram matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GramMatrix = np.inner(data, data)\n",
    "GramMatrix_scaled = center_and_normalise_kernel(GramMatrix)\n",
    "\n",
    "# heatmap + color map\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "plot = ax.imshow(GramMatrix_scaled) \n",
    "\n",
    "# set axes boundaries\n",
    "ax.set_xlim([0, data.shape[0]]) ; ax.set_ylim([0, data.shape[0]])\n",
    "\n",
    "# flip the y-axis\n",
    "ax.invert_yaxis() ; ax.xaxis.tick_top()\n",
    "\n",
    "# plot colorbar to the right\n",
    "plt.colorbar(plot, pad=0.1, fraction=0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.b\n",
    "\n",
    "__Question :__ What do you observe?\n",
    "\n",
    "__Answer :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe it would make more sense to look at other features to separates the two classes 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_adelie_chinstrap = pd.concat([penguins_features[penguins_labels[\"species_int\"].isin([0,1])],\n",
    "                                    penguins_labels[penguins_labels[\"species_int\"].isin([0,1])]],\n",
    "                                     axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(penguins_adelie_chinstrap, hue=\"species_int\",palette=\"bright\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.c\n",
    "\n",
    "__Question :__\n",
    "Which pair(s) of features could be used to have a better separation of these two classes?\n",
    "\n",
    "__Answer :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the steps in III.5. for this pair of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. SVM with  non-linear kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. RBF kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use an **RBF** (for **radial basis function**) kernel, for several values of the gamma parameter. In lecture the formula of the Gaussian kernel (or RBF kernel) with the sigma paramater was given to you:\n",
    "\n",
    "\\begin{align}\n",
    "k(x, x') = \\exp\\bigg[-\\frac{||x - x'||^2}{2 \\sigma^2}\\bigg]\n",
    "\\end{align}\n",
    "\n",
    "Another definition involves the gamma parameter, $\\gamma=\\frac{1}{2 \\sigma^{2}}$ : \n",
    "\n",
    "\\begin{align}\n",
    "k(x,x')=\\exp\\bigg[(-\\gamma\\||x - x'||^2\\bigg]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6.\n",
    "\n",
    "__Question :__ What is the gamma parameter in the RBF kernel formula?\n",
    "\n",
    "__Answer :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test different values of gamma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T14:45:39.706435Z",
     "start_time": "2019-11-05T14:45:39.680911Z"
    }
   },
   "outputs": [],
   "source": [
    "data = penguins_features_scaled[penguins_labels[\"species_int\"].isin([0,1])] \n",
    "data = np.array(data[[\"bill_depth_mm\", \"bill_length_mm\"]])\n",
    "\n",
    "labels = penguins_labels[penguins_labels[\"species_int\"].isin([0,1])]\n",
    "labels = np.array(labels[\"species_int\"])\n",
    "\n",
    "# gamma values\n",
    "gamma_range = np.linspace(0.01, 200, 20)\n",
    "\n",
    "for param in gamma_range:\n",
    "    clf = svm.SVC(kernel='rbf', C=0.7, gamma=param)\n",
    "    clf.fit(data, labels)\n",
    "    score = clf.score(data, labels)\n",
    "    print(\"gamma: {0:.2f} | score: {1:.2f}\".format(param, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7.\n",
    "\n",
    "__Question :__ What gamma value would we be tempted to take to get a better model?\n",
    "\n",
    "__Answer :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this model **generalise** well, i.e. will it be able to make good predictions on new, previously unseen data? \n",
    "\n",
    "To find out, we will separate the data into a __training set__ and a __test set__. The test set, being unknown at the time of training the model, is new data. For this we will use the function [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) of scikit-learn.\n",
    "\n",
    "We need to (1) do the split on the unstandardized features, then (2) standardize the training set, and finally (3) standardize the test set according to the variance and the mean of the training set features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T14:45:39.713509Z",
     "start_time": "2019-11-05T14:45:39.711346Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T14:45:39.739963Z",
     "start_time": "2019-11-05T14:45:39.715097Z"
    }
   },
   "outputs": [],
   "source": [
    "# split the dataset between train and test\n",
    "data = penguins_features[penguins_labels[\"species_int\"].isin([0,1])] \n",
    "data = np.array(data[[\"bill_depth_mm\", \"bill_length_mm\"]])\n",
    "\n",
    "labels = penguins_labels[penguins_labels[\"species_int\"].isin([0,1])]\n",
    "labels = np.array(labels[\"species_int\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, \n",
    "                                                    labels, \n",
    "                                                    test_size=.2, \n",
    "                                                    random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = std_scale.transform(X_train)\n",
    "X_test_scaled = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T14:45:39.739963Z",
     "start_time": "2019-11-05T14:45:39.715097Z"
    }
   },
   "outputs": [],
   "source": [
    "# test the performance for different values of gamma\n",
    "acc_train, acc_test = list(), list()\n",
    "gamma_range = np.linspace(0.01, 200, 20)\n",
    "for param in gamma_range:\n",
    "    clf = svm.SVC(kernel='rbf', C=0.7, gamma=param)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    acc_train.append(clf.score(X_train_scaled, y_train))\n",
    "    acc_test.append(clf.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the performance against the tested gamma values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T14:45:40.204403Z",
     "start_time": "2019-11-05T14:45:39.741607Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# plot train and test scores for different gamma values\n",
    "plt.plot(gamma_range, acc_train, label='train set', lw=4)\n",
    "plt.plot(gamma_range, acc_test, label='test set', lw=4)\n",
    "\n",
    "# add a legend\n",
    "plt.legend(loc='best', fontsize=12)\n",
    "\n",
    "# format the plot\n",
    "plt.xlabel(\"Gamma\", fontweight=\"bold\", fontsize=20)\n",
    "plt.ylabel(\"Performance\", fontweight=\"bold\", fontsize=20)\n",
    "plt.xticks(fontweight=\"bold\", fontsize=15)\n",
    "plt.yticks(fontweight=\"bold\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8.\n",
    "\n",
    "__Question :__ Do you observe a situation of overfitting? Where ? \n",
    "\n",
    "__Answer :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above makes us want to take a value of around 10 for the gamma parameter. But be careful ! If we take the parameter that works best on the test dataset, we may also overfit : we will then have used the test set to choose the best model, in other words, we will have \"seen\" the so-called \"unknown data\" during the learning phase (training)...\n",
    "\n",
    "To avoid this, we must make a __cross-validation__ on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the performance by varying the parameters *gamma* and *C*. We will use the [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) class of the *model_selection* module of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T14:45:40.208387Z",
     "start_time": "2019-11-05T14:45:40.205615Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T14:45:40.242347Z",
     "start_time": "2019-11-05T14:45:40.209870Z"
    }
   },
   "outputs": [],
   "source": [
    "# define a set of parameter to test\n",
    "parameters = {'gamma':[ 1, 10, 20, 50], \n",
    "             'C':[0.5, 0.7,1]}\n",
    "\n",
    "# initialize a model\n",
    "svc = svm.SVC(kernel='rbf')\n",
    "\n",
    "# initialize cross validation\n",
    "clf = GridSearchCV(estimator=svc, \n",
    "                   param_grid=parameters,\n",
    "                   cv=5)\n",
    "\n",
    "# run the cross validation using train dataset\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T14:45:40.499421Z",
     "start_time": "2019-11-05T14:45:40.243642Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "\n",
    "# format results from gridsearch\n",
    "scores = clf.cv_results_['mean_test_score'].reshape(len(parameters['gamma']), len(parameters['C']))\n",
    "print(scores)\n",
    "\n",
    "# plot performance scores\n",
    "# plt.imshow(scores, interpolation='none')\n",
    "plt.imshow(scores, interpolation='none', cmap=\"RdBu_r\")\n",
    "\n",
    "# add a colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# format the plot\n",
    "plt.title(\"Score\", fontweight=\"bold\", fontsize=20)\n",
    "plt.xlabel(\"C\", fontweight=\"bold\", fontsize=18)\n",
    "plt.ylabel(\"Gamma\", fontweight=\"bold\", fontsize=18)\n",
    "plt.ylim((-0.5, 3.5))\n",
    "plt.xticks(np.arange(len(parameters['C'])), parameters['C'], fontsize=15)\n",
    "plt.yticks(np.arange(len(parameters['gamma'])), parameters['gamma'], rotation=90, fontsize=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9.\n",
    "\n",
    "__Question :__ What is the role of parameter C? What do you observe when C is big?  \n",
    "\n",
    "__Answer :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10.\n",
    "\n",
    "__Question :__ Finally, what values of C and gamma will you take?\n",
    "\n",
    "__Answer :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the best SVM parameters for classification with the 4 features (*bill_depth_mm*,  *bill_length_mm*, *flipper_length_mm* and *body_mass_g*).\n",
    "\n",
    "__Question :__ Train a classification SVM to separate the species on the two problems (Adelie vs Gentoo, then Adelie vs Chinstrap). Train your SVM in cross-validation on the training set. What parameters can you vary? What is the performance of your optimal model _on the test set_? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Adelie (0) vs Gentoo (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T14:45:40.502862Z",
     "start_time": "2019-11-05T14:45:40.500881Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Adelie (0) vs Chinstrap (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T14:45:40.507053Z",
     "start_time": "2019-11-05T14:45:40.504726Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ How to build a multi-class SVM model that assigns a new observation to one of the three species Adelie (0), Chinstrap (1) or Gentoo (2)?\n",
    "\n",
    "__Answer :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
